\documentclass[bachelor, och, coursework, times]{SCWorks}
% параметр - тип обучения - одно из значений:
%    spec     - специальность
%    bachelor - бакалавриат (по умолчанию)
%    master   - магистратура
% параметр - форма обучения - одно из значений:
%    och   - очное (по умолчанию)
%    zaoch - заочное
% параметр - тип работы - одно из значений:
%    referat    - реферат
%    coursework - курсовая работа (по умолчанию)
%    diploma    - дипломная работа
%    pract      - отчет по практике
% параметр - включение шрифта
%    times    - включение шрифта Times New Roman (если установлен)
%               по умолчанию выключен
\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage{graphicx}

\usepackage[sort,compress]{cite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyvrb}
\usepackage{longtable}
\usepackage{array}
\usepackage[english,russian]{babel}


\usepackage[colorlinks=true]{hyperref}


\newcommand{\eqdef}{\stackrel {\rm def}{=}}

\newtheorem{lem}{Лемма}

\begin{document}

% Кафедра (в родительном падеже)
\chair{математической кибернетики и компьютерных наук}

% Тема работы
\worktitle{Реализация калькулятора с помощью лексического и синтаксического анализаторов}

% Курс
\course{2}

% Группа
\group{251}

% Факультет (в родительном падеже) (по умолчанию "факультета КНиИТ")
%\department{факультета КНиИТ}

% Специальность/направление код - наименование
%\napravlenie{010300 "--- Фундаментальная информатика и информационные технологии}
%\napravlenie{010500 "--- Математическое обеспечение и администрирование информационных систем}
%\napravlenie{230100 "--- Информатика и вычислительная техника}
\napravlenie{231000 "--- Программная инженерия}
%\napravlenie{090301 "--- Компьютерная безопасность}

% Для студентки. Для работы студента следующая команда не нужна.
%\studenttitle{Студентки}

% Фамилия, имя, отчество в родительном падеже
\studentName{Слуцкого Алексея Дмитриевича}

% Заведующий кафедрой
\chtitle{к.ф.-м.н.} % степень, звание
\chname{С.~В.~Миронов}

%Научный руководитель (для реферата преподаватель проверяющий работу)
\satitle{доцент, к.~ф.-м.~н.} %должность, степень, звание
\saname{Г.~Г.~Наркайтис}

% Руководитель практики от организации (только для практики,
% для остальных типов работ не используется)
\patitle{к.ф.-м.н., доцент}
\paname{А.~С.~Петров}

% Семестр (только для практики, для остальных
% типов работ не используется)
\term{2}

% Наименование практики (только для практики, для остальных
% типов работ не используется)
\practtype{производственно-технологическая}

% Продолжительность практики (количество недель) (только для практики,
% для остальных типов работ не используется)
\duration{3}

% Даты начала и окончания практики (только для практики, для остальных
% типов работ не используется)
\practStart{01.01.2012}
\practFinish{01.01.2012}

% Год выполнения отчета
\year{2016}

\MakeTitle

% Включение нумерации рисунков, формул и таблиц по разделам
% (по умолчанию - нумерация сквозная)
% (допускается оба вида нумерации)
%\secNumbering


\tableofcontents

% Раздел "Обозначения и сокращения". Может отсутствовать в работе
%\abbreviations
%\begin{description}
%    \item $|A|$  "--- количество элементов в конечном множестве $A$;
%    \item $\det B$  "--- определитель матрицы $B$;
%    \item ИНС "--- Искусственная нейронная сеть;
%    \item FANN "--- Feedforward Artifitial Neural Network
%\end{description}

% Раздел "Определения". Может отсутствовать в работе
%\definitions

% Раздел "Определения, обозначения и сокращения". Может отсутствовать в работе.
% Если присутствует, то заменяет собой разделы "Обозначения и сокращения" и "Определения"
%\defabbr


% Раздел "Введение"
\intro

Лексический и синтаксический анализ --- широко распространенный инструмент в информационных технологиях. Он используется для решения большого количества задач. От компиляторов, которые помогают программисту общаться с компьютером на языке высокого уровня до спеллчекеров, которые в наше время повсеместно --- в браузерах, мобильных приложениях, текстовых редакторах.

В последнее время большое значение приобрела задача построения синтаксических анализаторов для, так называемых, контекстно-свободных открытых языков, то есть языков, задаваемых контекстно-свободной грамматикой, которая может быть расширена.

Целью настоящей работы является создание калькулятора с использованием лексического и синтаксического анализаторов flex и bison. В данном курсовом проекте будет создана программа, получающая строку в виде алгебраического выражения и выдающая его результат.


\section{Структура формальных грамматик}
\subsection{Лексический анализатор}

Лексический анализ в информатике --- это процесс разбиения входных данных на последовательности символов, которые именуются "токенами". Группа символов, распознанная как токен, называется лексемой. Каждый токен однозначно характеризует лексему. А лексема, в свою очередь, однозначно определяет некоторую конструкцию языка. При лексическом анализе распознаются и выделяются лексемы из входной последовательности.

Лексический анализ проводится на основе заданного алфавита или набора языков, и грамматика языка задает список лексем, которые допустимо встретить во входных данных.
Традиционно принято организовывать входную последовательность как поток. При таком подходе процесс сам управляет выборкой символов из входного потока.

Распознавание лексем осуществляется путем их классификации согласно грамматике языка. 
И если очередная последовательность символов не соответствует ни одному типу допустимых лексем, то она считается специальным токеном-ошибкой.

Лексический анализатор --- это программа, которая осуществляет лексический анализ.
То, как будет представлен результат работы лексического анализатора в основном зависит от версии компилятора, но в общем виде его можно представить как таблицу лексем, где для каждой лексемы хранится необходимая служебная информация.

Обычно лексический анализатор работает в 2 этапа: сканирование и оценка.

На первом этапе формируется конечный автомат, характеризуемый регулярными выражениями, то есть собирается информация о том, какие токены допустимы в данном примере. Например, токен "вещественное число" может представляться в виде двух последовательностей цифр, разделенных точкой.

На втором этапе осуществляется разбор входной последовательности, происходит процесс распознавания токенов. Поочередно просматриваются элементы последовательности, пока не встретится запрещенный для данного токена символ. В сложных примерах может возникать ситуация, когда правила разбора не позволяют одним проходом однозначно идентифицировать все лексемы, тогда потребуется возврат назад по читаемой последовательности.

Полученные в результате анализа лексемы передаются синтаксическому анализатору.~\cite{Compilers}

\subsection{Синтаксический анализатор}

Синтаксический анализ --- это сопоставление последовательного набора лексем формального языка с его формальной грамматикой.
В процессе анализа входные данные представляются в виде дерева, так как оно хорошо подходит для дальнейшей обработки. Это может быть дерево составляющих, дерево зависимостей, другие структуры или сочетания нескольких способов представления.

Во время синтаксического анализа производится проверка корректности данных, представленных в виде последовательности токенов и совокупности таблиц, и преобразование программы во внутреннюю форму, удобную для последующей обработки. Обычно применяется совместно с лексическим анализом.

Задачи синтаксического анализа:
\begin{itemize}
\item определить, совпадает ли структура цепочки лексем со структурой, заданной синтаксисом языка;
\item зафиксировать данную структуру.
\end{itemize}

Синтаксический анализатор --- это программа, выполняющая синтаксический анализ.
Формально синтаксический анализатор является вычислимой функцией двух аргументов:
\begin{itemize}
\item Входная строка $w = a_1...a_n$ длины $|w| = n$, где $a_i \in T$, $1 \leqslant i \leqslant n$;
\item KC-грамматика $G = \{N, T, P, S\}$, где $S$ --- стартовый нетерминальный символ грамматики, $P$ --- правила языка, $T$ --- терминалы, $N$ --- нетерминальные символы языка.
\end{itemize}

Функция осуществляет построение и, если входная строка $w$ принадлежит языку $L(G)$, заданному грамматикой $G$, выдает дерево вывода $T_G$, этой строки в грамматике $G$ или $false$ - в противном случае.

На этапе синтаксического анализа устанавливается порядок следования символов в программе и становится ясной общая структура программы. Таким образом, анализатор должен понимать контекст, в котором производятся вычисления и учитывать уже прочитанные символы.

Чтобы построить синтаксический анализатор выражений языка используют несколько различных методов.

Рекурсивный нисходящий синтаксический анализатор представляется в виде рекурсивных функций, вызывающих друг друга, которые обрабатывают выражение. Если работа анализатора происходит в компиляторе, то генерируется объектный код, который соответствует исходному тексту программы.
А в интерпретаторе анализатор вычисляет значение заданного выражения.

Синтаксические анализаторы могут быть построены автоматически из определений языка. Такие анализаторы называются управляемыми таблицей, они создаются генераторами программ. В общем случае такие анализаторы обеспечивают более быструю работу, но процесс их создания достаточно трудоемкий, в частности потребуется форматировать абстрактное синтаксическое дерево.

Этап синтаксического анализа является ключевым, так как он непосредственно взаимодействует с лексической фазой и обеспечивает создание основы для работы компилятора.~\cite{Compilers}

\section{Реализация формальных грамматик на языке C}
\subsection{Flex}

Flex --- это инструмент для лексического анализа текста, который генерирует лексические анализаторы. На базе пакетов GNU заменяет UNIX-генератор Lex, при этом имеет аналогичную функциональность и расшифровывается как "Fast LEX".

Flex генерирует программы, распознающие шаблоны в тексте. Он создает программу, которая, используя заданные правила поиска, использует их в шаблонах. Преимущество Flex в простоте задания правил по сравнению с написанием собственных инструментов для поиска по шаблону.

Генератор получает на вход цепочки символов и правила выделения лексем, которые необходимо выполнить в случае успеха распознавания. После выполнения в качестве выходных данных выдает код анализатора в виде функции на языке С.

Полученную функцию часто используют совместно с генераторами синтаксических анализаторов. Они используют для поиска следующей лексемы функцию yylex(), которую сгенерировал Flex. Обычно Flex используют с YACC или GNU bison. 

% %
Flex работает по следующему принципу. Сначала подготавливается спецификация лексического анализатора на языке Lex --- получается файл lex.l. Потом полученный файл компилируется Lex-ом для получения программы на языке С. Результат - lex.yy.c. Эта программа содержит диаграмму переходов в виде таблицы, построенной по регулярным выражениям файла lex.l и программу, использующую эту таблицу для распознавания лексем.

\begin{figure}  [!ht]
	\centering
	\includegraphics[width=15cm]{lexanalis.jpg}
\end{figure}

Действия с регулярными выражениями представляются в виде фрагментов кода на языке С, которые переносятся в lex.yy.c. Далее полученная программа lex.yy.c компилируется стандартным С компилятором, в результате чего создается программа a.out, которая и является лексическим анализатором, преобразовывающим входную последовательность символов в набор токенов.




Программа Flex содержит 3 раздела, отделяющиеся строкой «\%\%»: \\
Блок объявлений \\
\%\% \\
Блок правил \\
\%\% \\
Блок вспомогательных процедур \\

Раздел объявлений включается в себя именованные константы, объявления переменных, макросов и регулярные определения.

Раздел правил представляется в виде: \\
$s_1$ \{$instruction_1$\} \\
$s_2$ \{$instruction_2$\} \\
$s_3$ \{$instruction_3$\}, \\

где $s_i$ --- регулярное выражение, а $instruction_i$ --- фрагмент кода, который необходимо выполнить лексическому анализатору, если лексема соответствует шаблону $s_i$.

Третий раздел представляет собой различные пользовательские функции, которые могут быть скомпилированы отдельно и загружены совместно с лексическим анализатором.

Лексический анализатор, созданный Flex, работает вместе с синаксическим анализатором в связке. Когда синтаксический анализатор активирует лексический, то последний начинает чтение оставшейся части входной последовательности по одному символу, пока сохраняется соответствие с одним из регулярных выражений $s_i$. Далее выполняется действие $instruction_i$.

Лексический анализатор возвращает синтаксическому анализатору только один параметр --- найденный токен. Для передачи информации об этом токене используется глобальная переменная yylval.~\cite{Hunter}

\subsection{Bison}

Bison --- это инструмент для грамматического разбора текста, который генерирует синтаксические анализаторы на основе грамматики, описанной в нотации BNF (форма Бэкуса-Наура) или контекстно-свободной грамматики.

GNU Bison может использоваться для преобразования входной последовательности токенов в структурированный формат для дальнейшей обработки. На выходе выдает программу-парсер на языке С.

Bison работает только с грамматиками класса LALR(1), то есть необходимо, чтобы была возможность разобрать любую последовательность, заглядывая вперед не более, чем на одну лексему.

Чтобы Bison смог разобрать программу на некотором языке, нужно чтобы данный язык был описан контекстно-свободной грамматикой. Таким образом, любая синтаксическая группа должна составляться из составных частей. При этом допустимо рекурсивное определение, однако в таком случае необходимо присутствие хотя бы одного правила, выводящего из рекурсии.

Код анализатора --- это код, определяющий функцию yyparse, которая реализует грамматику. Также для корректной работы необходимы дополнительные функции. Одна из них --- лексический анализатор.

Главная задача Bison --- это объединение лексем в группы в с соответствии с правилами грамматики. Часто Bison используют совместно с генератором лексических анализаторов Flex. И Bison вызывает лексический анализатор, когда ему необходима очередная лексема.

Общая структура программы выглядит так: \\
\%\{ \\
Объявления C \\
\%\} \\
Объявления Bison \\
\%\% \\
Правила грамматики \\
\%\% \\
Дополнительный код на C \\

Раздел Объявления С состоит из определений типов, переменных, функций, которые необходимы для выполнения действий правил грамматики, а также макросов и других директив препроцессора.

Объявления Bison определяют имена нетерминальных и терминальных символов, описывают типы данных семантических значений и задают приоритет операций.

Правила грамматики устанавливают связи между нетерминальными символами, а именно из каких частей они состоят. Должно быть хотя бы одно правило грамматики.

Дополнительный код на С копируется в конец файла анализатора. К примеру, тут может находиться функция yylex(). Эта секция в отличие от предыдущей может остаться пустой. Тогда допустимо не ставить последние \%\%.

Правила грамматики представляются в следующем виде:

$expr$: \quad $components$ \{$action$\} ; \\

где $expr$ --- это описываемый правилом нетерминальный символ,\\ $components$ --- различные терминальные и нетерминальные символы, объединяемые этим правилом, $action$ --- действие, которое необходимо выполнить в случае соответствия текущего набора типов лексем данной грамматике.

Действие выглядит в виде кода на С, который должен выполняться, если правилу соответствует данных текст. Обычно действие вычисляет семантическое значение группы, исходя из семантических значений компонент.~\cite{opennet}







\subsection{Makefile}

Мой проект состоит из нескольких отдельных программ. При добавлении новой функции калькулятору, внесении правок в исходный код, отладке программы приходится перекомпилировать каждый файл и собирать его в единое целое по несколько раз. Чтобы не делать это вручную, можно воспользоваться стандартной утилитой GNU make. Она самостоятельно принимает решение о том, какие файлы нужно перекомпилировать и выполняет необходимые действия.

Для того, чтобы использовать make, нужно создать make-файл, описывающий зависимости между частями проекта и содержащий команды для их обновления. Обычно исполняемый файл зависит от объектных файлов, которые, в свою очередь, зависят от файлов с исходным кодом.

После создания make-файла достаточно просто ввести команду <<make>> и все необходимые файлы будут перекомпилированны. Утилита make на основе данных о последних модификациях частей проекта обновляет устаревшие файлы. Для всех них выполняются указанные в makefile команды. ~\cite{make1}

В общем случае makefile выглядит как набор из правил следующего вида:

$target$: \quad $dependencies$ \\
$ $\quad \quad \quad \quad \quad \quad $command$

Target представляет собой имя файла, которое генерируется в процессе сборки. Dependencies --- файл, используемый для порождения цели. Command --- действие, которое необходимо выполнить, если dependencies устарели.

Правило описывает, каким образом необходимо обновлять файлы или как должно выполняться некоторое действие. Файл должен быть перекомпилирован всякий раз, когда изменилась одна из его зависимостей. При это все зависимости, которые генерируются автоматически, должный быть первыми обновлены. 

По умолчанию, make начинает работать с первой встреченной целью. Эта цель выбирается целью по умолчанию. Главная цель --- это цель, которую стремится достичь make, как результат своей работы. Другие правила обрабатываются только потому, что их цели являются прямыми или косвенными зависимостями для главной цели. ~\cite{make2}

Makefile может состоять из пяти видов конструкций: явные и неявные правила, директивы, определения переменных и комментарии.

В явное правиле перечисляются файлы, от которых зависит цель, и могут быть заданы команды, необходимые для обновления цели.

Неявное правило описывает, как следует обновлять некоторую группу файлов, подходящих под определенный шаблон. Оно определят, как цель зависит от файла с таким же именем и задает команду для создания или обновления цели.

Определение переменной представлено в виде строки, в которой переменной присваивается некоторое текстовое значение. Далее это значение может быть подставлено в нужное место текста.

Директива определяет специальное действие, которое необходимо совершить во время чтения make-файла (например, определение многострочной переменной или подключение другого make-файла).

Символ <<\#>> обозначает комментарий. Весь текст от него и до конца строки будет игнорирован. 

\section{Пример реализации арифметических операций}
\subsection{Сложение и вычитание}
Реализуем сначала простейший калькулятор, который будет поддерживать только 2 операции --- <<+>> и <<->>.
Для этого понадобится два файла исходного кода. Один из них будет генерировать лексический анализатор (calc1.l), другой --- синтаксический (calc1.y).

На результат выражения пробелы никак не влияют, поэтому сделаем допущение, что любые пробел лексер будет просто игнорировать (строка 9 приложения \ref{pril-2}). Тогда остается только распознать числа и знаки.

Число можно представить в виде $[0-9]+$. Это означает, что число есть последовательность одной или более цифр от 0 до 9 (строки 10-13 приложения \ref{pril-2}).

А все то, что не подходит под определения числа, будет считать арифметическим знаком (строки 14-16 приложения \ref{pril-2}). При этом нам совершенно не важно, действительно ли это знак или эта лексема вообще не является допустимой. В последнем случае ошибку обработает уже Bison.

Полный код программы calc1.l находится в приложении \ref{pril-2}.

Calc1.y будет, в свою очередь обрабатывать лексемы, которые выделил Flex в соответствии с написанной грамматикой (строки 22-33 приложения \ref{pril-3}).

В форме Бэкуса-Наура ее можно представить в виде: \linebreak
<expr> ::= <expr> + <expr> | <expr> - <expr> | NUMBER,

где NUMBER --- это уже определенный Flex-ом токен, соответствующий целому числу.

Полный код программы calc1.y находится в приложении \ref{pril-3}.

Сборку исходных кодов анализаторов в законченную программу будет осуществлять Makefile.

Полный код программы Makefile находится в приложении \ref{pril-1}.

\subsection{Приоритеты}
Добавим в калькулятор возможность разбора выражения, содержащего операции с приоритетом. То есть теперь, допустимыми арифметическими действиями являются <<+>>, <<->>, <<*>>,<</>>. Также добавим возможность заключать выражения в скобки.

Файл calc2.l ничем не будет отличаться от предыдущего. Новые знаки операций и скобки также будут подходить под определение <<не является числом>> (строки 14-16 приложения \ref{pril-4}).

Полный код программы calc2.l находится в приложении \ref{pril-4}.

В файле calc2.y, во-первых, необходимо указать, что лево-ассоциативные операции <<*>> и <</>> обладают большим приоритетом по сравнению с <<+>> и <<->> (строки 13-14 приложения \ref{pril-5}).

Во-вторых следует изменить определение $expr$ (строки 23-49 приложения \ref{pril-5}): 

<expr> ::= <expr> + <expr> | <expr> - <expr> | <expr> * <expr> | <expr> / <expr> | NUMBER.

Полный код программы calc2.y находится в приложении \ref{pril-5}.

\subsection{Типизация}
Пусть теперь калькулятор должен поддерживать 3 стандартных типа языка С: long long, long double и long double complex. Причем должно быть реализовано приведение типов к большему.

Так, например, для входных данных 5/2 калькулятор должен выдать результат, равный двум, а для 5.0/2 равный 2,5.

Как изменится calc3.l по сравнению с предыдущими версиями?
Во-первых, необходимо определить число с дробной частью. На языке С это будет записано в виде $[0-9]+.[0-9]+$. Это значит, что нецелое число есть конкатенация двух последовательностей цифр ненулевой длины, разделенная символом <<.>>(строки 22-26 приложения \ref{pril-6}).

Не теряя общности для простоты реализации будем выделять комплексное число из входной последовательности, полагая его действительную часть равной нулю.
Тогда его можно представить в следующем виде: \linebreak
$[0-9]+.[0-9]+[i] | [0-9]+[i]$

Впервые в записи шаблона встретился символ <<|>>. Он означает логическое <<ИЛИ>>. Таким образом, последовательность символов подходит под данный шаблон, если она соответствует хотя бы одному из подшаблонов, разделенных вертикальной чертой.

Значит, комплексное число --- это некоторое целое или дробное число, после которого сразу же стоит символ <<i>> (строки 13-20 приложения  \ref{pril-6}).

Полный код программы calc3.l находится в приложении \ref{pril-6}.

С добавление типизации появляется некоторая сложность. Становится неясно, каким образом тогда хранить информацию о токене NUMBER, ведь теперь он может быть представлен одним из 3 различных типов.

Чтобы решить эту проблему, можно воспользоваться стандартной структурой языка C union. Эта структура отличается тем, что может иметь несколько различных представлений. При этом все данные разделяют одну и ту же ячейку памяти. ~\cite{kernigan}

Заведем структуру $value\_t$. У нее будет 2 поля --- union, который может принимать 3 различных типа, и <<флажок>> type, который показывает, какой на данный момент тип используется в объединении (строки 13-22 приложения \ref{pril-6}).

Теперь, при соответствии любому правилу с знаком арифметического действия, необходимо проверить, какой из типов наибольший и выполнить приведение двух аргументов к этому типу (строки 90-94 приложения \ref{pril-7}).

Само приведение будет осуществлять функция $cast\_value$ (строки 11-35 приложения \ref{pril-7}), реализация которой выполнена в виде вложенных $switch$ на основе типа, к которому необходимо выполнить приведение.

После приведения типов для обоих аргументов, с помощью $switch$ можно выполнить арифметическое действие с нужными полями union.

Полный код программы calc3.y находится в приложении \ref{pril-7}.
















% Раздел "Заключение"
\conclusion
В ходе выполнения курсовой работы были изучены и отработаны навыки по следующим темам:
\begin{itemize}
	\item написание программ на языке С;
	\item работа с GNU Linux;
	\item формальные грамматики;
	\item разработка лексического анализатора;
	\item разработка синтаксического анализатора;
	\item работа с Makefile;
	\item структура union языка С;
\end{itemize}


%Библиографический список, составленный вручную, без использования BibTeX
%
%\begin{thebibliography}{99}
%  \bibitem{Ione} Источник 1.
%  \bibitem{Itwo} Источник 2
%\end{thebibliography}

%Библиографический список, составленный с помощью BibTeX
%
\bibliographystyle{gost780uv}
\bibliography{thesis}

% Окончание основного документа и начало приложений
% Каждая последующая секция документа будет являться приложением
\appendix

\section{Листинг программы <<Makefile>>}\label{pril-1}

\begin{Verbatim}[fontsize=\small, numbers=left]
calculator: lex.calc.c calc.tab.h calc.tab.c
	gcc calc.tab.c lex.calc.c -o calc

lex.calc.c: calc.l
	$(LEX) $^

calc.tab.c: calc.y
	$(YACC) $^

calc.tab.h: calc.y
	$(YACC) -d $^
\end{Verbatim}

\section{Листинг программы <<calc1.l>>}\label{pril-2}

\begin{Verbatim}[fontsize=\small, numbers=left]
%{
#include <stdio.h>
#include "calc.tab.h"
%}

%option prefix="calc"

%%
[' ']     ;
[0-9]+    {
              calclval = atoi(calctext);
              return NUMBER;
          }
[^0-9]    {             
              return calctext[0]; 
          }
%%
\end{Verbatim}

\section{Листинг программы <<calc1.y>>}\label{pril-3}

\begin{Verbatim}[fontsize=\small, numbers=left]
%{
#include <stdio.h>
#include <string.h>
%}

%name-prefix "calc"
%file-prefix "calc"

%start str

%token NUMBER

%left '+' '-'

%%   
str:     expr '\n'
         {
             printf("%d\n", $1);
         }
         ;

expr:    expr '+' expr
         {
             $$ = $1 + $3;
         }
         |
         expr '-' expr
         {
             $$ = $1 - $3;
         }
         |
         NUMBER
         ;       
%%

extern struct calc_buffer_state* calc_scan_string(char* str);

main(int argc, char* argv[])
{
	int buf_size = 2;
	int i;
	for (i = 1; i < argc; i++)
	{
		buf_size += strlen(argv[i]);
	}

	char buf[buf_size];
	char* ptr = buf;
	for (i = 1; i < argc; ++i)
	{
		char* arg;
		for (arg = argv[i]; *arg; )
			*ptr++ = *arg++;
	}
	*ptr++ = '\n';
	*ptr = 0;

	struct calc_buffer_state* buffer = calc_scan_string(buf);
	calcparse();
}

calcerror(s)
{
	printf("error\n");
}

calcwrap()
{
	return(1);
}
\end{Verbatim}



\section{Листинг программы <<calc2.l>>}\label{pril-4}

\begin{Verbatim}[fontsize=\small, numbers=left]
%{
#include <stdio.h>
#include "calc.tab.h"
%}

%option prefix="calc"

%%
[' ']     ;
[0-9]+    {
              calclval = atoi(calctext);
              return NUMBER;
          }
[^0-9]    {             
              return calctext[0]; 
          }
%%
\end{Verbatim}

\section{Листинг программы <<calc2.y>>}\label{pril-5}

\begin{Verbatim}[fontsize=\small, numbers=left]
%{
#include <stdio.h>
#include <string.h>
%}

%name-prefix "calc"
%file-prefix "calc"

%start str

%token NUMBER

%left '+' '-'
%left '*' '/'

%%   
str:     expr '\n'
         {
             printf("%d\n", $1);
         }
         ;

expr:    '(' expr ')'
         {
             $$ = $2;
         }
         |
         expr '+' expr
         {
             $$ = $1 + $3;
         }
         |
         expr '-' expr
         {
             $$ = $1 - $3;
         }
         |
         expr '*' expr
         {
             $$ = $1 * $3;
         }
         |
         expr '/' expr
         {
             $$ = $1 / $3;
         }
         |
         NUMBER
         ;      
%%

extern struct calc_buffer_state* calc_scan_string(char* str);

main(int argc, char* argv[])
{
	int buf_size = 2;
	int i;
	for (i = 1; i < argc; i++)
	{
		buf_size += strlen(argv[i]);
	}

	char buf[buf_size];
	char* ptr = buf;
	for (i = 1; i < argc; ++i)
	{
		char* arg;
		for (arg = argv[i]; *arg; )
			*ptr++ = *arg++;
	}
	*ptr++ = '\n';
	*ptr = 0;

	struct calc_buffer_state* buffer = calc_scan_string(buf);
	calcparse();
}

calcerror(s)
{
	printf("error\n");
}

calcwrap()
{
	return(1);
}
\end{Verbatim}



\section{Листинг программы <<calc3.l>>}\label{pril-6}

\begin{Verbatim}[fontsize=\small, numbers=left]
%{
#include <stdio.h>
#include <complex.h>
#include "values.h"
#include "calc.tab.h"
%}

%option prefix="calc"

%%
[' ']                      ;

[0-9]+\.[0-9]+[i] | 
[0-9]+[i]              {
                           calctext[strlen(calctext) - 1] = 0;
                           calclval.number.type = VT_COMPLEX;
                           calclval.number.xldl = 0 + atof(calctext) * I;
                           return NUMBER;

                       }

[0-9]+\.[0-9]+         {
                           calclval.number.type = VT_FLOAT;
                           calclval.number.ldl = atof(calctext);
                           return NUMBER;
                       }

[0-9]+                 {
                           calclval.number.type = VT_INT;
                           calclval.number.llint = atoi(calctext);
                           return NUMBER;
                       }

[^0-9]                 {             
                           return calctext[0]; 
                       }
%%
\end{Verbatim}

\section{Листинг программы <<calc3.y>>}\label{pril-7}

\begin{Verbatim}[fontsize=\small, numbers=left]
%{
#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <complex.h>

#include "values.h"

#define max(a, b) ((a > b) ? a : b)

void cast_value(value_t* value, value_type_t target)
{
	switch (target)
	{
		case VT_FLOAT:
			switch (value->type)
			{
				case VT_INT:
					value->ldl = value->llint;
					break;
			}
			break;
		case VT_COMPLEX:
			switch (value->type)
			{
				case VT_INT:
					value->xldl = value->llint + 0 * I;
					break;
				case VT_FLOAT:
					value->xldl = value->ldl + 0 * I;
					break;
			}
	}
	value->type = target;
}
%}

%name-prefix "calc"
%file-prefix "calc"

%union 
{	
	value_t number;
};

%start str

%token <number> NUMBER

%left '+' '-'
%left '*' '/'
%type <number> expr

%%   
str:		expr '\n'
			{
				switch ($1.type)
				{
			 		case VT_INT:
						printf("%lld\n", $1.llint);
						break;
			 		case VT_FLOAT:
						printf("%Lf\n", $1.ldl);
						break;
					case VT_COMPLEX:
						if (cimagl($1.xldl) >= 0.0)
						{
							printf("%Lf + %Lfi\n", 
							creall($1.xldl), 
							cimagl($1.xldl));
						}
						else
						{
							printf("%Lf - %Lfi\n", 
							creall($1.xldl), 
							-cimagl($1.xldl));
						}
						break;
				}
			}
         	;

expr:    '(' expr ')'
         {
			 $$ = $2;
         }
         |
         expr '+' expr
         {
			 value_type_t max_type = max($1.type, $3.type);

			 $$.type = max_type;
			 cast_value(&$1, max_type);
			 cast_value(&$3, max_type);

			 switch (max_type)
			 {
			 	case VT_INT:
					 $$.llint = $1.llint + $3.llint;
					 break;
			 	case VT_FLOAT:
					 $$.ldl = $1.ldl + $3.ldl;
					 break;
			 	case VT_COMPLEX:
					$$.xldl = $1.xldl + $3.xldl;
					break;
			 }
         }
         |
		 expr '-' expr
         {
			 value_type_t max_type = max($1.type, $3.type);

			 $$.type = max_type;
			 cast_value(&$1, max_type);
			 cast_value(&$3, max_type);

			 switch (max_type)
			 {
			 	case VT_INT:
					 $$.llint = $1.llint - $3.llint;
					 break;
			 	case VT_FLOAT:
					 $$.ldl = $1.ldl - $3.ldl;
					 break;
			 	case VT_COMPLEX:
					$$.xldl = $1.xldl - $3.xldl;
					break;
			 }
         }
         |
		 expr '*' expr
         {
			 value_type_t max_type = max($1.type, $3.type);

			 $$.type = max_type;
			 cast_value(&$1, max_type);
			 cast_value(&$3, max_type);

			 switch (max_type)
			 {
			 	case VT_INT:
					 $$.llint = $1.llint * $3.llint;
					 break;
			 	case VT_FLOAT:
					 $$.ldl = $1.ldl * $3.ldl;
					 break;
			 	case VT_COMPLEX:
					$$.xldl = $1.xldl * $3.xldl;
					break;
			 }
         }
         |
		 expr '/' expr
         {
			 value_type_t max_type = max($1.type, $3.type);

			 $$.type = max_type;
			 cast_value(&$1, max_type);
			 cast_value(&$3, max_type);

			 switch (max_type)
			 {
			 	case VT_INT:
					if ($3.llint != 0)
					{
						$$.llint = $1.llint / $3.llint;
					}
					else
					{
						calcerror();
						return 1;
					}
					break;
			 	case VT_FLOAT:
					if ($3.ldl != 0.0)
					{
						$$.ldl = $1.ldl / $3.ldl;
					}
					else
					{
						calcerror();
						return 1;
					}
					break;
			 	case VT_COMPLEX:
					if (creall($3.xldl) != 0.0 || 
					cimagl($3.xldl) != 0.0)
					{
						$$.xldl = $1.xldl / $3.xldl;
					}
					else
					{
						calcerror();
						return 1;
					}
					break;
			 }
         }
         |
		 NUMBER
         ;    
%%

extern struct calc_buffer_state* calc_scan_string(char* str);

main(int argc, char* argv[])
{
	int buf_size = 2;
	int i;
	for (i = 1; i < argc; i++)
	{
		buf_size += strlen(argv[i]);
	}

	char buf[buf_size];
	char* ptr = buf;
	for (i = 1; i < argc; ++i)
	{
		char* arg;
		for (arg = argv[i]; *arg; )
			*ptr++ = *arg++;
	}
	*ptr++ = '\n';
	*ptr = 0;

	struct calc_buffer_state* buffer = calc_scan_string(buf);
	calcparse();
}

calcerror(s)
{
	printf("error\n");
}

calcwrap()
{
	return(1);
}


\end{Verbatim}

\section{Листинг программы <<values.h>>}\label{pril-8}

\begin{Verbatim}[fontsize=\small, numbers=left]
#ifndef _VALUES_
#define _VALUES_

typedef enum 
{ 
	VT_INT, 
	VT_FLOAT,
	VT_COMPLEX
} value_type_t;

typedef long double complex complex_t;

typedef struct
{
	value_type_t type;
	union
	{
		long long llint;
		long double ldl;
		complex_t xldl;
	};
} value_t;

#endif
\end{Verbatim}
















\end{document}
